{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "104b3af0-bf4c-4e5a-acb7-62c88293d5f8",
      "metadata": {
        "id": "104b3af0-bf4c-4e5a-acb7-62c88293d5f8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.utils import class_weight\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os, shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8286439c-ddca-4890-b5fe-3136aa1f2505",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8286439c-ddca-4890-b5fe-3136aa1f2505",
        "outputId": "733d687b-fb12-4cc4-aaf2-5325408c49bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/My Drive/chest-xrays'\n",
        "\n",
        "# training set\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "train_normal = os.path.join(train_dir, 'NORMAL')\n",
        "train_pneumonia = os.path.join(train_dir, 'PNEUMONIA')\n",
        "\n",
        "# validation set\n",
        "val_dir = os.path.join(base_dir, 'val')\n",
        "val_normal = os.path.join(val_dir, 'NORMAL')\n",
        "val_pneumonia = os.path.join(val_dir, 'PNEUMONIA')\n",
        "\n",
        "# test set\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ],
      "metadata": {
        "id": "ruPQBH3J7Wh5"
      },
      "id": "ruPQBH3J7Wh5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b856007d-ad80-4fb9-a31e-df84ba1d0e17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b856007d-ad80-4fb9-a31e-df84ba1d0e17",
        "outputId": "ee1ef9a9-3e8f-4c93-d253-a490161f77f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training images: 5226\n",
            "Total validation images: 16\n",
            "Total test images: 624\n"
          ]
        }
      ],
      "source": [
        "# count images per set\n",
        "print('Total training images:', len(os.listdir(train_normal) + os.listdir(train_pneumonia)))\n",
        "print('Total validation images:', len(os.listdir(val_normal) + os.listdir(val_pneumonia)))\n",
        "print('Total test images:', len(os.listdir(test_dir)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_all_image_paths(base_dir):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for split in ['train', 'val']:\n",
        "        for class_name in ['NORMAL', 'PNEUMONIA']:\n",
        "            class_dir = os.path.join(base_dir, split, class_name)\n",
        "            for fname in os.listdir(class_dir):\n",
        "                full_path = os.path.join(class_dir, fname)\n",
        "                if os.path.isfile(full_path):\n",
        "                    image_paths.append(full_path)\n",
        "                    labels.append(class_name)\n",
        "    return np.array(image_paths), np.array(labels)\n",
        "\n",
        "def reorganize_split_dataset(image_paths, labels, output_base, test_size=0.2):\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        image_paths, labels, test_size=test_size, stratify=labels, random_state=42\n",
        "    )\n",
        "\n",
        "    for subset, x, y in [('train', x_train, y_train), ('val', x_val, y_val)]:\n",
        "        for src, label in zip(x, y):\n",
        "            dest_dir = os.path.join(output_base, subset, label)\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            dest_path = os.path.join(dest_dir, os.path.basename(src))\n",
        "            shutil.copy2(src, dest_path)\n",
        "\n",
        "# paths\n",
        "original_data = '/content/drive/My Drive/chest-xrays'\n",
        "output_data = '/content/drive/My Drive/chest-xrays-split'\n",
        "\n",
        "# run\n",
        "paths, labels = get_all_image_paths(original_data)\n",
        "reorganize_split_dataset(paths, labels, output_data)"
      ],
      "metadata": {
        "id": "K1Rgx3c25xuY"
      },
      "id": "K1Rgx3c25xuY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_gen = ImageDataGenerator(rescale=1./255,\n",
        "                               rotation_range=20,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               zoom_range=0.1,\n",
        "                               horizontal_flip=True).flow_from_directory(\n",
        "    '/content/drive/My Drive/chest-xrays-split/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "    '/content/drive/My Drive/chest-xrays-split/val',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3_HtPMm7Qkf",
        "outputId": "6695fba1-fca5-4456-a99c-041a901d727b"
      },
      "id": "N3_HtPMm7Qkf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4193 images belonging to 2 classes.\n",
            "Found 1049 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "img_dir = '/content/drive/My Drive/chest-xrays/test'\n",
        "filenames = os.listdir(img_dir)\n",
        "df = pd.DataFrame({'filename': filenames})\n",
        "\n",
        "test_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    directory=img_dir,\n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zfyAOd_wRG_",
        "outputId": "6edf5ae4-1433-4c2e-cfeb-5b63ab05835d"
      },
      "id": "1zfyAOd_wRG_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 624 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "# Initialize a pre-trained model\n",
        "pretrained_model = tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3)\n",
        "    )\n",
        "\n",
        "# We don't need to train the pre-trained model — we just want to fine-tune it later\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "transfer_model = Sequential()\n",
        "transfer_model.add(pretrained_model)\n",
        "transfer_model.add(GlobalAveragePooling2D())\n",
        "transfer_model.add(Dense(128, activation='relu'))\n",
        "transfer_model.add(Dropout(0.5))\n",
        "transfer_model.add(Dense(1, activation='sigmoid'))\n",
        "transfer_model.summary()\n",
        "\n",
        "transfer_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 1e-3: accuracy & loss increasing\n",
        "# 1e-2: loss still increasing, accuracy flat\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Calculate steps_per_epoch to ensure complete batches\n",
        "#steps_per_epoch = len(x_train_balanced) // BATCH_SIZE\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_labels = train_gen.classes\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(class_labels),\n",
        "    y=class_labels\n",
        ")\n",
        "\n",
        "# Convert to dictionary\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=2,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_model.weights.h5',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True\n",
        ")\n",
        "\n",
        "history = transfer_model.fit(\n",
        "    train_gen,\n",
        "    epochs=5,\n",
        "    validation_data=val_gen,\n",
        "    class_weight=class_weights_dict,\n",
        "    callbacks=[early_stop, checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "2c8CFCc9HRz-",
        "outputId": "5c9aa801-a616-4f0c-83fd-6cbd82d5bd7e"
      },
      "id": "2c8CFCc9HRz-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m262,272\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,827,201\u001b[0m (90.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,827,201</span> (90.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m262,401\u001b[0m (1.00 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">262,401</span> (1.00 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,564,800\u001b[0m (89.89 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> (89.89 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1167s\u001b[0m 9s/step - accuracy: 0.8354 - loss: 0.4483 - val_accuracy: 0.8665 - val_loss: 0.3314\n",
            "Epoch 2/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1060s\u001b[0m 8s/step - accuracy: 0.9176 - loss: 0.2152 - val_accuracy: 0.8541 - val_loss: 0.3612\n",
            "Epoch 3/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1096s\u001b[0m 8s/step - accuracy: 0.9176 - loss: 0.2183 - val_accuracy: 0.9399 - val_loss: 0.1420\n",
            "Epoch 4/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1062s\u001b[0m 8s/step - accuracy: 0.9339 - loss: 0.1752 - val_accuracy: 0.9552 - val_loss: 0.1297\n",
            "Epoch 5/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1062s\u001b[0m 8s/step - accuracy: 0.9396 - loss: 0.1723 - val_accuracy: 0.9209 - val_loss: 0.1897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze some of the deeper convolutional layers\n",
        "for layer in pretrained_model.layers[-10:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "transfer_model.compile(optimizer=Adam(1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_ft = transfer_model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5,\n",
        "    callbacks=[early_stop, checkpoint],\n",
        "    class_weight=class_weights_dict\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX46xLMg951u",
        "outputId": "7d8c8aa6-579a-455f-e473-04861e60ab2f"
      },
      "id": "ZX46xLMg951u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1208s\u001b[0m 9s/step - accuracy: 0.9269 - loss: 0.2646 - val_accuracy: 0.8856 - val_loss: 0.2819\n",
            "Epoch 2/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1172s\u001b[0m 9s/step - accuracy: 0.9395 - loss: 0.1891 - val_accuracy: 0.9190 - val_loss: 0.2057\n",
            "Epoch 3/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1252s\u001b[0m 9s/step - accuracy: 0.9428 - loss: 0.1559 - val_accuracy: 0.9314 - val_loss: 0.1804\n",
            "Epoch 4/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1227s\u001b[0m 9s/step - accuracy: 0.9462 - loss: 0.1490 - val_accuracy: 0.9380 - val_loss: 0.1628\n",
            "Epoch 5/5\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1287s\u001b[0m 9s/step - accuracy: 0.9441 - loss: 0.1556 - val_accuracy: 0.9571 - val_loss: 0.1367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "transfer_model.load_weights('best_model.weights.h5')\n",
        "# Get predicted class labels\n",
        "y_pred_probs = transfer_model.predict(test_gen)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).ravel()\n",
        "\n",
        "# Map numeric predictions to class labels\n",
        "label_map = {0: 'NORMAL', 1: 'PNEUMONIA'}\n",
        "y_labels = [label_map[p] for p in y_pred]\n",
        "\n",
        "# Get corresponding filenames\n",
        "file_names = [os.path.basename(path) for path in test_gen.filenames]\n",
        "\n",
        "# Create DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': file_names,\n",
        "    'class': y_labels\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "submission_df.to_csv('submission7.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBsxeZWVhico",
        "outputId": "083c40ee-77c5-4291-d02f-5e6025bb4a78"
      },
      "id": "aBsxeZWVhico",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 28 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 8s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission7.csv')\n",
        "\n",
        "# submission3 = class weights w/ 132 steps per epoch\n",
        "# submission6 = fine-tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "B63xoaDdyc8p",
        "outputId": "ef172d1e-1c1b-48c1-9a67-e0995fd133d4"
      },
      "id": "B63xoaDdyc8p",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_94629642-3d8e-4023-b0d1-3bebd40f6854\", \"submission7.csv\", 13060)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5892d53-286c-4169-b5c3-c6d17d455b1c",
      "metadata": {
        "id": "d5892d53-286c-4169-b5c3-c6d17d455b1c"
      },
      "outputs": [],
      "source": [
        "# final accuracy\n",
        "acc = history_fine.history['accuracy']\n",
        "print('Training accuracy:', acc[-1])\n",
        "val_acc = history_fine.history['val_accuracy']\n",
        "print('Validation accuracy:', val_acc[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f2da9e8-f8c7-457b-b26d-c33d04ed1730",
      "metadata": {
        "id": "5f2da9e8-f8c7-457b-b26d-c33d04ed1730"
      },
      "outputs": [],
      "source": [
        "# accuracy plots\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.figure()\n",
        "plt.plot(epochs, acc, label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}